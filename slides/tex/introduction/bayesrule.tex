\subsection{Bayes' Rule}
	\begin{frame}
		\[ \P( \beta \mid \alpha ) = \frac{\P( \alpha \mid \beta )}{\P( \alpha )} \P( \beta ) \]
		\begin{itemize}
			\item Prior probability: $\P( \beta )$
			\item Posterior probability: $\P( \beta \mid \alpha )$
			\item Data Likelihood: $\P( \alpha \mid \beta )$
			\item Evidence probability: $\P( \alpha )$
		\end{itemize}
		\begin{itemize}
			\item Bayes' rule can be seen as a way of \alert{revising beliefs} in light of new information/knowledge: start with $\P( \beta )$, observe $\alpha$ then set $\P( \beta )' = \P( \beta \mid \alpha )$
			\item This way of thinking is known as \alert{Bayesian Reasoning}
		\end{itemize}
	\end{frame}