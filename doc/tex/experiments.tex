\section{Experiments, Results and Discussion}
\label{sec:experiments}

In order to evaluate the quality of our approaches, we learned Bayesian networks using Order-based greedy search and different initialization strategies from several data sets commonly used for benchmarking. The names and relevant characteristics of the data sets\footnote{These datasets were extracted from http://urlearning.org/datasets.html} used are shown in Table~\ref{tab:datasets}, where the density of a graph is defined as the ratio of the number of edges and the number of nodes.
	\begin{table}[ h ]
		\centering
		\begin{tabular}{ | l | c | c | c | }
			\hline
			Dataset & n (\#attributes) & N (\#instances) & Density of $\overline G$ \\ \hline
			Census & 15 & 30168 & 2.85 \\ \hline
			Letter & 17 & 20000 & 2.41 \\ \hline
			Image & 20 & 2310 & 2.45 \\ \hline
			Mushroom & 23 & 8124 & 2.91 \\ \hline
			Sensors & 25 & 5456 & 3.00 \\ \hline
			SteelPlates & 28 & 1941 & 2.18 \\ \hline
			Epigenetics & 30 & 72228 & 1.87 \\ \hline
			Alarm & 37 & 1000 & 1.98 \\ \hline
			Spectf & 45 & 267 & 1.76 \\ \hline
			LungCancer & 57 & 27 & 1.44 \\ \hline
		\end{tabular}
		\caption{Data sets characteristics}
		\label{tab:datasets}
	\end{table}
For each dataset we performed 1000 runs of Order-Based Greedy Search with a limit of 3  parents ($d=3$) and 100 iterations ($K=100$), except for the  LungCancer dataset where only 100 runs were performed due to the limited computational resources. We used the BIC score and found the best parent sets for a given ordering by exhaustive search.

We compared our proposed initialization strategies, which we call DFS- and FAS-based, against the standard approach of randomly generating an order (called Random). For each strategy, we compared the best score obtained over all runs (Best score), the average initial score (i.e., the score of the best DAG consistent with the initial ordering), the average best score (i.e., the average of the scores of the local searches) and the average number of iterations that local search took to converge. The results are shown in Table~\ref{tab:comparison}.
	\input{addons/results}
The results show that in most of the datasets with less than 25 attributes, the Random strategy finds the highest-scoring networks over all runs, even though it finds worse networks on average. The best initial solutions are found by the FAS-based strategy followed by the DFS-based strategy. For datasets with more than 25 variables, Random is less effective in finding high-scoring networks, except for the LungCancer (which has very little data). These results suggest that more informed approaches to generating initial orderings might be more effective in high dimensionality domains, or when the number of restarts is limited e.g.~for computational reasons. The proposed strategies are also more robust, which can be seen by the smaller variance of the average initial and best scores. 

The results also suggest that the proposed strategies are more effective than Random in datasets for which the graph $\overline G$ is sparser (smaller  density), showing that pruning the space of orderings can be effective in those cases. The initial orderings provided by the proposed strategies speed up convergence of the local search, as can be seen by the smaller number of average iterations for those strategies in the table.

Overall, the new heuristics are able to improve the accuracy of Order-Based Greedy Search with only a small overhead. Although the differences observed in our experiments were small, we expect greater differences in domains of higher dimensionality.

% Converge curves
% \input{addons/curves}
