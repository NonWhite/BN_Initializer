\section{Generating informed initial solutions}
\label{sec:improve}

As with most local search approaches, the selection of a good initial solution is crucial for avoiding convergence to poor local maxima in Order-Based Learning. Traditionally, this is attempted by randomly generating initial solutions (i.e., a node ordering) in order to cover as much as possible of the search space. In this section, we devise methods that take advantage of the structure of the problem to produce better initial solutions. 

% \subsection{Random solution}
% \label{subsec:randomapproach}
% 	This is the most common and easy-to-implement approach used.

\subsection{DFS-based approach}
\label{subsec:dfsapproach}
We can exploit the information provided by the graph $\overline G$ (defined in equation~\ref{eq:bestparents}) to reduce the space of topological orderings and avoid generating orderings which are guaranteed sub-optimal. Assume the best parent sets are unique, and consider a pair of nodes $X_i,X_j$ in $\overline G$ such that $X_j$ is parent of $X_i$ but there is not arc from $X_i$ into $X_j$. Then, no optimal ordering can have $X_i$ preceding $X_j$ (this can easily be shown by contradiction). Hence, only topological orderings consistent with $\overline G$ are potential candidates for optimality, and this number can be much smaller than the full space of orderings. To see this clearly, consider Figure~\ref{fig:example} which shows a possible graph $\overline G$ and the corresponding consistent orderings. As can be noticed we have 14 consistent  orderings out of $4! = 24$ possible topological orders. This difference is likely to increase as the number of variables increases.
	\begin{figure}[H]
	 	\centering
	 	\begin{subfigure}{.48\textwidth}
	 		\centering
			\input{networks/example}
			%\caption{}
	 	\end{subfigure}
	 	\begin{subfigure}{.48\textwidth}
	 		\centering
			\includegraphics[height=3cm]{images/dfsorders}
			%\caption{}
			%\label{fig:dfsorders}
	 	\end{subfigure}
		\caption{A an example of a fraph $\overline{G}$ and its consistent topological orderings}
                \label{fig:example}
	\end{figure}
	% \input{addons/dfs_orders}
	Taking into consideration the previous analysis, we propose the following algorithm to generate initial solutions. Take as input the graph $\overline G$ and mark all nodes as unvisited. While there is an unvisited node, select an unvisited node $X_i$ uniformly at random and add to the list the nodes visited by a depth-first search (DFS) tree rooted at $X_i$. Finally, return $L$, an ordering of the nodes.
	%\input{addons/dfsalgorithm}
	
\subsection{FAS-based approach}
\label{subsec:fasapproach}
The DFS approach can be seen as removing edges from $\overline G$ such as to make it a DAG (more specifically, a tree), and then extracting a consistent topological ordering. That approach hence considers that all edges are equally relevant in terms of avoiding poor local maxima. We can estimate the arguably relevance of an edge $X_j \rightarrow X_i$ by
\begin{equation}
  \label{eq:weight}
  W_{ji} = {sc}( X_i , {Pa}^*( X_i ) ) - {sc}( X_i , {Pa}^*( X_i ) \setminus \{ X_j \} ) ,
\end{equation}
where ${Pa}^*( X_i )$ denotes the best parent set for $X_i$ (i.e., its parents in $\overline G$). The weight $W_{ji}$ represents the cost of removing $X_j$ from the set ${Pa}^*( X_i )$ and it is always a positive number because ${Pa}( X_i )$ maximizes the score for $X_i$. A small value means that the parent $X_j$ is not very relevant to $X_i$ (in that sense), while a large value denotes the opposite. For instance, in the weighted graph $\overline G$ in Figure~\ref{fig:example}, the edge $C \rightarrow D$ is less relevant than the edges $A \rightarrow D$, which in turn is less relevant than the edge $B  \rightarrow D$. 

   The main idea of our second heuristic is to penalize orderings which violate an edge $X_i \rightarrow X_j$ in $\overline G$ by their associated cost $W_{ij}$. We then wish to find a topological ordering of $\overline G$ that violates the least cost of edges. Given a directed graph $G = (V,E)$, a set $F \subseteq E$ is called a Feedback Arc Set (FAS) if every (directed) cycle of $G$ contains at least one edge in $F$. In other words, $F$ is an edge set that if removed makes the graph $G$ acyclic~\cite{DF01}. If we assume that the cost of an ordering of $\overline G$ is the sum of the weights of the violated (or removed) edges, we can formulate the problem of finding a minimum cost ordering of $\overline G$ as a Minimum Cost Feedback Arc Set Problem (min-cost FAS): given the weighted directed graph $\overline{G}$ with weights $W_{ij}$ given by equation \eqref{eq:weight}, find a FAS $F$ such that
\begin{equation}
  \label{eq:mincostfas}
  F = \min_{G - F \text{ is a DAG}} \sum_{X_i \rightarrow X_j \in E} W_{ij} .
\end{equation}
Even though the problem is NP-hard, there are efficient and effective approximation algorithms like the one described in Algorithm~\ref{code:fasapprox}~\cite{DF01}.

\begin{lstlisting}[ caption = FAS approximation , label = code:fasapprox ]
	MinimumCostFAS( Graph |$G$| ) : Return FAS |$F$|
	   |$F$| = empty set
	   While there is a cycle |$C$| on |$G$| do
	   	|$W_{min}$| = lowest weight of all edges in |$C$|
		For each edge |$(u,v) \in C$| do
		   |$W_{uv} = W_{uv} - W_{min}$|
		   If |$W_{uv} = 0$| add to |$F$|
	   For each edge in |$F$|, add it to |$G$| if does not build a cycle
	   Return |$F$|
\end{lstlisting}

We can now describe our second heuristic for generating initial solutions, based on the minimum cost FAS problem: take the weighted graph $\overline G$ with weights $W_{ij}$ as input, and find a min-cost FAS $F$; remove the edges in $F$ from $\overline G$ and return a topological order of the obtained graph $\overline G - F$ (this can be done by performing a DFS starting with root nodes).
	%\input{addons/fasalgorithm}

% These new methods for generating initial solutions will be used in next section to learn Bayesian networks with multiple data sets.