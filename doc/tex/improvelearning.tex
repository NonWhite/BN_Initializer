\section{Generating informed initial solutions}
\label{sec:improve}

As with most local search approaches, the selection of a good initial solution that avoids poor local maxima is crucial for finding good solutions. Traditionally, this is attempted by randomly generating initial solutions (DAGs, pDAGs or orderings) in order to cover as much as possible of the space. In this section, we devise methods that take advantage of the structure of the problem to produce better initial solutions. Although we focus on Order-Based search, our methods could be used for any of the other greedy approaches discussed in Section~\ref{sec:learning} doing some modifications that will be explained in Section~\ref{sec:conclusions}.

% \subsection{Random solution}
% \label{subsec:randomapproach}
% 	This is the most common and easy-to-implement approach used.

\subsection{DFS-based solution}
\label{subsec:dfsapproach}
	It can be noticed that generating random solutions means having a huge search space ($n!$) for datasets with $n > 10$, but this search space can be reduced using the graph $\overline G$ (defined in equation~\ref{eq:bestparents}). This graph tell us some information about if it is good that a variable $X_j \in {Pa}( X_i )$ should be before $X_i$ in an order, because it has as relationships the best parent set for each $X_i$.\\
	For instance, Figure~\ref{fig:dfsorders} shows the possible orders consistent with the relationships in the graph $\overline G$ (Figure~\ref{fig:example}). As can be noticed we have 14 possible orders given $\overline{G}$, but $4! = 24$ possible orders using a random approach. So we reduce the search space and also improve the possibilities that getting a good initial order. Also, the difference could be greater in problems with more variables.
	\begin{figure}[H]
	 	\centering
	 	\begin{subfigure}{.48\textwidth}
	 		\centering
			\input{networks/example}
			\caption{}
			\label{fig:example}
	 	\end{subfigure}
	 	\begin{subfigure}{.48\textwidth}
	 		\centering
			\includegraphics[height=3cm]{images/dfsorders}
			\caption{}
			\label{fig:dfsorders}
	 	\end{subfigure}
		\caption{(a) Graph $\overline{G}$. (b) Possible orders for graph $\overline G$}
	\end{figure}
	% \input{addons/dfs_orders}
	Taking into consideration the previous analysis, we propose the following algorithm to generate initial solutions:
	\begin{lstlisting}[ caption = DFS-based method , label = code:dfsbased ]
	DFS_Based( Graph |$\overline G$| ) : return Order |$L$| consistent with |$\overline G$|
	   |$L$| = empty list
	   While there are nodes not visited on |$\overline G$| do
		|$X_k$| = random not visited node
		|${DFS}( \overline G , X_k , L )$|
	   Return |$L$|
	\end{lstlisting}
	Where ${DFS}$ performs a depth-first search on $\overline G$ using $X_k$ as root and add each node $X_v$ visited to the order $L$.
	
\subsection{FAS-based solution}
\label{subsec:fasapproach}

In this subsection, we first explained the generic problem and one of the variants of the Feedback Arc Set (FAS) Problem. After that, a reduction of the learning structure Bayesian network problem will be explained in order to propose a new algorithm for generating initial solutions.

\subsubsection{Feedback Arc Set Problem} \label{subsub:fasp}

The generic problem is stated as: given a graph $G = ( V , E )$, a set $F \subseteq E$ is called the Feedback Arc Set (FAS) if every cycle of $G$ has at least one edge in $F$. In other words, $F$ is the edge set that if you put if off the graph $G$, it becomes a DAG~\cite{DF01}.\\
There are some variants of this problem, but we only focus on finding the minimum cost FAS $F$ from a weighted directed graph $G$ defined in equation~\ref{eq:mincostfas}.
\begin{equation}
	\label{eq:mincostfas}
	F_{G} = \min_{G - F \text{ is a DAG}} \sum_{(u,v) \in E} W_{uv} ,
\end{equation}
where $W_{uv}$ is the weight of the edge from $u$ to $v$ on $G$. Although this variant becomes NP-hard, there are some approximation algorithms like the one that is below.
\begin{lstlisting}[ caption = FAS approximation , label = code:fasapprox ]
	MinimumCostFAS( Graph |$G$| ) : Return FAS |$F$|
	   |$F$| = empty set
	   While there is a cycle |$C$| on |$G$| do
	   	|$W_{min}$| = lowest weight of all edges in |$C$|
		For each edge |$(u,v) \in C$| do
		   |$W_{uv} = W_{uv} - W_{min}$|
		   If |$W_{uv} = 0$| add to |$F$|
	   For each edge in |$F$|, add it to |$G$| if does not build a cycle
	   Return |$F$|
\end{lstlisting}

\subsubsection{Algorithm for initial solutions}
\label{subsub:fasalgorithm}
	A possible problem with the previous method (DFS-based) is that uses $\overline G$ and generate orders consistent with it using a random node as root, but does not consider that some edges are more important than others and could be better to keep them on the graph because they maximize the score. It also means that some nodes could be more important than others in the best parent set of a variable. This importance of an edge could be represented as follows:
		\begin{equation}
			\label{eq:weight}
			W_{ji} = {sc}( X_i , P ) - {sc}( X_i , P \setminus \{ X_j \} ) ,
		\end{equation}
	where $W_{ji}$ is the weight of the edge that goes from $X_j$ to $X_i$ and $P$ is the best parents set for $X_i$. This formula represents the cost of getting $X_j$ out of the set $P$ and it is always a positive number because $P$ maximizes the score for $X_i$. When the value is so small, it means the parent $X_j$ could be more important. On the contrary if the weight is so big, this means that $X_j$ is not so important in $P$. For instance, graph $\overline G$ in Figure~\ref{fig:example} shows that $C$ is more important than $B$ and $A$ as a parent of $D$ because that edge has a lower value.\\
	%Using this weight edge, we can prove that the problem can be reduce with the following equations:
	%\input{addons/fasprove}
        %This means that the score of the DAG $G^*$ plus the score of the deleted arcs from $\overline{G}$ give an approximation for $G^*$, and also that $G^*$ could be a subgraph of $\overline{G}$. 
        We can now describe our second heuristic for generating initial solutions, based on the minimum cost FAS problem:
	\begin{lstlisting}[ caption = FAS-based method , label = code:fasbased ]
	FAS_Based( Graph |$\overline G$| ) : return Order consistent with |$\overline G$|
	   Add weights |$W_{ji}$| to edges in |$\overline G$|
	   |$F$| = MinimumCostFAS( |$\overline G$| )
	   |$G = \overline G - F$|
	   Return topological( |$G$| )
	\end{lstlisting}

These new methods for generating initial solutions will be used in next section to learn Bayesian networks with multiple data sets.