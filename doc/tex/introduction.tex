\section{Introduction}
\label{sec:introduction}

Bayesian Networks are space-efficient representations of complex
multivariate probability distributions~\cite{VJensen01}. They are
defined by two components: (i) a directed acyclic graph (DAG) encoding the (in)dependence relationships among the variables in the model; and (ii) a collection of local conditional probability distributions of each variable given its parents.

Manually specifying a Bayesian network is a difficult task, and practitioners often resort to ``learning'' the model from data. A common approach to learning a Bayesian network consists of associating every DAG with a polynomial-time computable score value and searching for structures with high score values~\cite{Cooper92,MDL94,Margaritis03,TK05}. The score value of a structure usually rewards structures that assign high probability of observing the data set (i.e., the data likelihood) and penalizes the complexity of the model (i.e., the number of parameters). Some examples are the Bayesian Information Criterion (BIC)~\cite{BIC91}, the Minimum Description Length (MDL)~\cite{MDL94} and the Bayesian Dirichlet score (BD)~\cite{BD95}. An alternative approach is to learn the DAG by multiple conditional independence hypothesis testing \cite{Spirtes95,ci}. Although both approaches can recover the true DAG (if one exists) given infinite data and computational resources, testing for independence introduces a lot of false positives and it is often followed by a score-based approach \cite{maxmin}. 

Score-based Bayesian network learning from data is a NP-hard problem~\cite{MSResearch04}, even when the in-degree (i.e., maximum number of parents) of the graph is bounded. For this reason, the most common approach is to resort local search methods that find an approximate solution \cite{FNP99,Maxwell02}. A popular and very effective method for learning Bayesian networks is to perform a local search on the space of topological orderings \cite{TK05}. The search is usually initialized with an ordering sampled uniformly at random from the space of orderings. This can make the search converge to a poor local optima unless more sophisticate techniques are employed \cite{ENF02}, which can add significant computational overhead. An alternative solution is to initialize the search in high-scoring regions.

% As with other local search methods, order-based learning is vulnerable to poor local maxima unless a strategy for avoiding low score regions is used. One such strategy is the use of non-greedy heuristics that allow moving for lower value solutions during search in order to escape local maxima~\cite{ENF02}. Another strategy is to use \emph{good initialization heuristics} that attempt to start the search in regions of high local maxima. Traditionally, order-based search is initialized with a topological ordering sampled uniformly at random from the space of orderings.

In this work we design two new heuristics for generating good initial solutions to order-based Bayesian network structure learning. The first heuristic follows the observation that only orderings consistent with a relaxed version of the problem (in which cycles are permitted) can lead to an optimal structure. Although this heuristic biases the search away from regions which are \emph{guaranteed} to be sub-optimal, it generates orderings with equal probability in any other region. Our second heuristic refines the first one by selecting high scoring orderings among the ones that are consistent with the relaxed version solution. We do this by reducing the problem to a variant of the Feedback Arc Set Problem (FASP), which is the problem of transforming a cyclic direct graph into a DAG. Our experiments show that using these new methods improves the quality of order-based local search.

The rest of this paper is structured as follows: we begin in Section~\ref{sec:learning} explaining greedy search approaches to learning Bayesian networks. Then in Section~\ref{sec:improve} we describe the new algorithms for generating initial solutions. Section~\ref{sec:experiments} shows the experiments using both approaches and comparing them (in scoring and number of iterations needed) with multiple data sets. Finally, in Section~\ref{sec:conclusions} we give
some conclusions about the new methods.
