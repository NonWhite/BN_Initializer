\section{Introduction}
\label{sec:introduction}

Bayesian Networks are models that represent efficiently probability distributions over the atributes of a data set. They are defined by two components:
\begin{itemize}
	\item A directed acyclic graph (DAG), where the nodes are the atributes of the data set and the edges encode the (in)dependence relationships among the atributes.
	\item The conditional probability distributions of the atributes given their parents. The latter are defined by the network's structure.
\end{itemize}
Formally, a Bayesian network is defined by:
\[ G = ( V , E ), \]
where $V = \{ X_1 , X_2 , \ldots , X_n \}$  is the set of attributes and
\[ P( X_1 , X_2 , \ldots , X_n ) = \prod_{i=1}^{n} P( X_i \mid {Pa}_G( X_i ) ),  \]
where ${Pa}_G( X_i )$ is the set of atributes that are parents of $X_i$ in $G$. This definition shows that having less parents for an atribute decrease the number of parameters required in the specification, but learning Bayesian networks from data is a NP-hard problem~\cite{MSResearch04} even when the in-degree (maximum number of parents) is bounded, for this reason, the common approach to solve this problem is to use local search methods, commonly using a scoring function, like the bayesian information criterion (BIC)~\cite{BIC91} or the minimum description length (MDL)~\cite{MDL94} or Bayesian Dirichlet score (BD)~\cite{BD95}.

% TODO: Describe other type of solutions for learning

In this article we propose new heuristics for generating good initial solutions to be fed into local search methods. We focus on order-based methods, but our technique can be exploited by any Bayesian net search procedure. We propose a new methods for generating informed initial solutions motivated by solutions of the Feedback Arc Set Problem (FASP). Our experiments show that using these new methods it is possible to learn better networks from data sets.

The article is structured as follows: We begin in Section~\ref{sec:learning} explaining the Greedy Search algorithm. In Section~\ref{sec:improve}, we describe the new algorithm for gener3ating initial solutions. Section~\ref{sec:experiments} shows the experiments using both approaches and comparing them (in time and scoring) with multiple data sets. Finally, in Section~\ref{sec:conclusions} we give some conclusions about the new methods.